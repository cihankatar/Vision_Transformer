{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "\n",
    "transform = ToTensor()\n",
    "\n",
    "train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n",
    "test_set = MNIST(root='./../datasets', train=False, download=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)\n",
    "\n",
    "for batch in train_loader:\n",
    "    images, targets = batch \n",
    "\n",
    "plt.imshow(images[0].squeeze())      #1x28x28--> 28x28\n",
    "\n",
    "\n",
    "def patching (images, patch_size):  \n",
    "   \n",
    "    h_patch,w_patch=patch_size\n",
    "\n",
    "    n, c, h, w = images.shape\n",
    "\n",
    "    patches = torch.zeros(n, n_patch ** 2, h * w / n_patch ** 2)\n",
    "    patch_size = h // n_patch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FAKE IMAGES \n",
    "hidth = 28\n",
    "witdh = 28\n",
    "chann= 1\n",
    "number_of_mages =50\n",
    "desired_token_lenght= 8 \n",
    "number_patches=7\n",
    "patch_size = hidth//number_patches\n",
    "\n",
    "\n",
    "fake_images = torch.rand(number_of_mages, chann, hidth, witdh)\n",
    "cls_t= nn.Parameter(torch.rand(1,desired_token_lenght)) \n",
    "\n",
    "patches=patchify(fake_images,number_patches)         \n",
    "linear_mapp = nn.Linear((hidth//number_patches)**2, desired_token_lenght)    # 1x16-->1x8 (in order to initialize and tokenize with random weights, pixels in each of patches to desired token lenghth\n",
    "tokens = linear_mapp(patches)                                                # tokenize the input \n",
    "\n",
    "print(patches.shape)\n",
    "print(tokens.shape)\n",
    "\n",
    "\n",
    "# adding cls_t to each of tokens // vstack = 1x8 to 49x8 => 50x8\n",
    "token_stack = torch.stack([torch.vstack((cls_t, tokens[i])) for i in range(len(tokens))]) \n",
    "\n",
    "pos_embed = nn.Parameter(torch.tensor(get_positional_embeddings(50, 8)))\n",
    "pos_embed = pos_embed.repeat(number_of_mages,1,1)\n",
    "\n",
    "out=token_stack+pos_embed\n",
    "\n",
    "out_numpy = out.cpu().detach().numpy()\n",
    "\n",
    "#plt.imshow(fake_images[2,0,:,:])\n",
    "#plt.imshow(out_numpy[2,:,:])\n",
    "\n",
    "print(f\"fake images shape     : {fake_images.shape}\") #fake images shape     : torch.Size([5, 1, 28, 28])\n",
    "print(f\"fake images shape     : {len(fake_images)}\")  #fake images shape     : 5\n",
    "print(f\"shape of patches      : {patches.shape}\")     #shape of patches      : torch.Size([5, 49, 16])\n",
    "print(f\"shape of tokens       : {tokens.shape}\")      #shape of tokens       : torch.Size([5, 49, 8])\n",
    "print(f\"shape of token_stack  : {type(token_stack)}\") #shape of token_stack  : torch.Size([5, 50, 8])\n",
    "print(f\"shape of pos_embed    : {type(pos_embed)}\")   #shape of pos_embed    : torch.Size([5, 50, 8])\n",
    "print(f\"shape of out          : {type(out)}\")         #shape of out          : torch.Size([5, 50, 8])\n",
    "\n",
    "x=torch.randn(70,50,8)\n",
    "models = MyViTBlock(hidden_d=8,n_heads=2)\n",
    "print(f'model output shape',models(x).shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
